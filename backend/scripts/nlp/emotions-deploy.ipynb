{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1aa8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "import boto3\n",
    "import csv\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a194d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bff79e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3031c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket = 'ad440-mpg-floop-export-storage'\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "obj = s3.Object(bucket, 'auto-floop-s3-export3-sagemaker.json')\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "client = boto3.client('sagemaker')\n",
    "\n",
    "prefix = \"sagemaker/blazingtext\"\n",
    "\n",
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa111c85",
   "metadata": {},
   "source": [
    "### Get Data\n",
    "* Get csv data (that we created in the emotions file) so we can use the analysis to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be34032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If the temperature in a pond is lower, then th...</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maybe there is a need to be clear about why th...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More details.  A lot happened.</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pronoun problem</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{{NAME}}, your handwriting is hard to read...p...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence   Emotion\n",
       "1  If the temperature in a pond is lower, then th...      Fear\n",
       "2  Maybe there is a need to be clear about why th...  Surprise\n",
       "3                     More details.  A lot happened.       Sad\n",
       "6                                    pronoun problem      Fear\n",
       "7  {{NAME}}, your handwriting is hard to read...p...     Angry"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get clean sentences and emotions\n",
    "df = pd.read_csv('sentenceEmotion.csv', index_col=[0])\n",
    "\n",
    "#remove all non-emotion data\n",
    "df = df[df.Emotion != 'none']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17bedbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1819 entries, 1 to 3236\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  1819 non-null   object\n",
      " 1   Emotion   1819 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 42.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4306793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fear        701\n",
       "Sad         414\n",
       "Surprise    317\n",
       "Happy       240\n",
       "Angry       147\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09364b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If the temperature in a pond is lower, then th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maybe there is a need to be clear about why th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More details.  A lot happened.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pronoun problem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{{NAME}}, your handwriting is hard to read...p...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Emotion\n",
       "1  If the temperature in a pond is lower, then th...       0\n",
       "2  Maybe there is a need to be clear about why th...       1\n",
       "3                     More details.  A lot happened.       2\n",
       "6                                    pronoun problem       0\n",
       "7  {{NAME}}, your handwriting is hard to read...p...       3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add categorical values to emotions for simplicity\n",
    "df['Emotion'] = pd.Categorical(pd.factorize(df.Emotion)[0])\n",
    "\n",
    "# Fear = 0\n",
    "# Surprise = 1\n",
    "# Sad = 2\n",
    "# Angry = 3\n",
    "# Happy = 4\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "007993d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    701\n",
       "2    414\n",
       "1    317\n",
       "4    240\n",
       "3    147\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1991c5a",
   "metadata": {},
   "source": [
    "### Prepare dataset \n",
    "The <b>label</b> needs to be in front with the emotional value and the sentence needs to be tokenized for the blazingtext algo to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbb29f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>if the temperature in a pond is lower then the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>maybe there is a need to be clear about why th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>more details . a lot happened .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>pronoun problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__3</td>\n",
       "      <td>{ { name } } your handwriting is hard to read ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>__label__0</td>\n",
       "      <td># 12 leave in square root form on these ! ( -1 )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>__label__4</td>\n",
       "      <td># 12 looks good !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>__label__4</td>\n",
       "      <td># 12 needs review . these functions are import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>__label__0</td>\n",
       "      <td># 12 needs unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>__label__0</td>\n",
       "      <td># 12 required a lot of work to show ... only h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Emotion                                           Sentence\n",
       "0     __label__0  if the temperature in a pond is lower then the...\n",
       "1     __label__1  maybe there is a need to be clear about why th...\n",
       "2     __label__2                    more details . a lot happened .\n",
       "3     __label__0                                    pronoun problem\n",
       "4     __label__3  { { name } } your handwriting is hard to read ...\n",
       "...          ...                                                ...\n",
       "1814  __label__0   # 12 leave in square root form on these ! ( -1 )\n",
       "1815  __label__4                                  # 12 looks good !\n",
       "1816  __label__4  # 12 needs review . these functions are import...\n",
       "1817  __label__0                                    # 12 needs unit\n",
       "1818  __label__0  # 12 required a lot of work to show ... only h...\n",
       "\n",
       "[1819 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(review):\n",
    "    # delete commas and quotation marks, apply tokenization and join back into a string separating by spaces\n",
    "    return ' '.join([str(token) for token in nltk.word_tokenize(str(review).replace(',', '').replace('\"', '').lower())])\n",
    "     \n",
    "def prepare_data(df):\n",
    "    df['Emotion'] = df['Emotion'].map(lambda Emotion : '__label__{}'.format(str(Emotion).replace('__label__', '')))\n",
    "    df['Sentence'] = df['Sentence'].map(lambda Sentence : tokenize(Sentence)) # Replace all None\n",
    "    return df\n",
    " \n",
    " \n",
    " \n",
    "df_blazingtext = df[['Emotion', 'Sentence']].reset_index(drop=True)\n",
    "df_blazingtext = prepare_data(df_blazingtext)\n",
    "df_blazingtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e07c798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split all data into 80% train and 20% holdout\n",
    "df_train, df_validation = train_test_split(df_blazingtext, test_size=0.20, stratify=df_blazingtext['Emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ef651",
   "metadata": {},
   "source": [
    "Upload training and validation csv files to notebook and s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3762b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blazingtext_train_path = './train.csv'\n",
    "df_train[['Emotion', 'Sentence']].to_csv(blazingtext_train_path, index=False, header=False, sep=' ')\n",
    " \n",
    "blazingtext_validation_path = './validation.csv'\n",
    "df_validation[['Emotion', 'Sentence']].to_csv(blazingtext_validation_path, index=False, header=False, sep=' ')\n",
    "\n",
    "s3_output_location = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    " \n",
    "s3_train_data = sess.upload_data(bucket=bucket, key_prefix=prefix, path=blazingtext_train_path)\n",
    "s3_validation_data = sess.upload_data(bucket=bucket, key_prefix=prefix, path=blazingtext_validation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0bb52",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a718cd",
   "metadata": {},
   "source": [
    "Set up estimator object. The estimator launches the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30faf73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=region_name,\n",
    "    framework='blazingtext'\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a6966",
   "metadata": {},
   "source": [
    "resource configurations for the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436dd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size=30,\n",
    "    output_path = s3_output_location,\n",
    "    max_run=8000,\n",
    "    hyperparameters={\n",
    "        # supervised text classification\n",
    "        \"mode\": \"supervised\",\n",
    "        # number of passes through the dataset\n",
    "        \"epochs\": 1,\n",
    "        # discard words that pass through this amount of times\n",
    "        \"min_count\": 2,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"vector_dim\": 10,\n",
    "        \"early_stopping\": True,\n",
    "        \"patience\": 4,\n",
    "        \"min_epochs\": 5,\n",
    "        # number of words\n",
    "        \"word_ngrams\": 2,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d9a72",
   "metadata": {},
   "source": [
    "Prepare how the data channels and the algorithm communicate. The objects are created from the data channels and put in a dictionary for the algorithm.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e387d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583c05b",
   "metadata": {},
   "source": [
    "### Train the algo\n",
    "it may take a bit. \n",
    "Once the job has finished a \"Job complete\" message will be printed. The trained model can be found in the S3 bucket that was setup as output_path in the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc043ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 22:04:33 Starting - Starting the training job...\n",
      "2022-03-24 22:04:56 Starting - Preparing the instances for trainingProfilerReport-1648159473: InProgress\n",
      ".........\n",
      "2022-03-24 22:06:16 Downloading - Downloading input data.....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[03/24/2022 22:07:09 WARNING 140148829439808] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/24/2022 22:07:09 WARNING 140148829439808] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/24/2022 22:07:09 INFO 140148829439808] nvidia-smi took: 0.02523350715637207 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[03/24/2022 22:07:09 INFO 140148829439808] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[03/24/2022 22:07:09 INFO 140148829439808] Processing /opt/ml/input/data/train/train.csv . File size: 0.13014984130859375 MB\u001b[0m\n",
      "\u001b[34m[03/24/2022 22:07:09 INFO 140148829439808] Processing /opt/ml/input/data/validation/validation.csv . File size: 0.03947925567626953 MB\u001b[0m\n",
      "\u001b[34mRead 0M words\u001b[0m\n",
      "\u001b[34mNumber of words:  1715\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/validation.csv\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m##### Alpha: -0.0003  Progress: 100.63%  Million Words/sec: 0.27 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 1\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 0.27 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 0.27\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 0.10\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.3649\u001b[0m\n",
      "\u001b[34mNumber of train examples: 1455\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.3626\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 364\u001b[0m\n",
      "\n",
      "2022-03-24 22:07:21 Training - Training image download completed. Training in progress.\n",
      "2022-03-24 22:07:21 Uploading - Uploading generated training model\n",
      "2022-03-24 22:07:57 Completed - Training job completed\n",
      "Training seconds: 102\n",
      "Billable seconds: 102\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf2da64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-03-24 22:08:37 Starting - Preparing the instances for training\n",
      "2022-03-24 22:08:37 Downloading - Downloading input data\n",
      "2022-03-24 22:08:37 Training - Training image download completed. Training in progress.\n",
      "2022-03-24 22:08:37 Uploading - Uploading generated training model\n",
      "2022-03-24 22:08:37 Completed - Training job completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No metrics called train:mean_rho found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train:accuracy</td>\n",
       "      <td>0.3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation:accuracy</td>\n",
       "      <td>0.3626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp          metric_name   value\n",
       "0        0.0       train:accuracy  0.3649\n",
       "1        0.0  validation:accuracy  0.3626"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.latest_training_job.wait(logs=False)\n",
    "estimator.training_job_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1975d",
   "metadata": {},
   "source": [
    "### Hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e7818",
   "metadata": {},
   "source": [
    "delpoy the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "505c93db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "emotion_model = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", serializer=JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1885d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': ['Generating random paragraphs can be an excellent way for writers to get their creative flow going at the beginning of the day .', 'The writer has no idea what topic the random paragraph will be about when it appears .']}\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'Generating random paragraphs can be an excellent way for writers to get their creative flow going at the beginning of the day.',\n",
    "    'The writer has no idea what topic the random paragraph will be about when it appears.'\n",
    "]\n",
    "\n",
    "# using the same nltk tokenizer that we used during data preparation for training\n",
    "tokenized_sentences = [\" \".join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "#payload = {\"instances\": tokenized_sentences, \"configuration\": {\"k\": 2}}\n",
    "payload = {\"instances\": tokenized_sentences}\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb7e4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = emotion_model.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e15e3bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__1\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.20009951293468475\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__0\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.20043520629405975\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))\n",
    "\n",
    "# Fear = 0\n",
    "# Surprise = 1\n",
    "# Sad = 2\n",
    "# Angry = 3\n",
    "# Happy = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90240465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': ['__label__1'], 'prob': [0.20009951293468475]}, {'label': ['__label__0'], 'prob': [0.20043520629405975]}]\n",
      "Predicted emotion: 1\n",
      "Predicted emotion: 0\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "\n",
    "for prediction in predictions:\n",
    "    print('Predicted emotion: {}'.format(prediction['label'][0].lstrip('__label__')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d31ce",
   "metadata": {},
   "source": [
    "### Delete the endpoint!!\n",
    "save costs and delete the endpoint on sagemaker console- there isn't a working command line right now.\n",
    "1. aws sagemaker screen\n",
    "2. left navigation bar- click \"inference\"\n",
    "3. choose the most recent blazingtext endpoint name that was auto created running this model\n",
    "4. top 'actions' dropdown - choose delete\n",
    "5. verify endpoint is deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf65260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
